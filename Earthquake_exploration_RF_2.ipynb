{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\",\n",
    "                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize 1% of samples data, first 100 datapoints\n",
    "train_ad_sample_df = train['acoustic_data'].values[::100]\n",
    "train_ttf_sample_df = train['time_to_failure'].values[::100]\n",
    "\n",
    "#function for plotting based on both features\n",
    "def plot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df, title=\"Acoustic data and time to failure: 1% sampled data\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    plt.title(title)\n",
    "    plt.plot(train_ad_sample_df, color='r')\n",
    "    ax1.set_ylabel('acoustic data', color='r')\n",
    "    plt.legend(['acoustic data'], loc=(0.01, 0.95))\n",
    "    ax2 = ax1.twinx()\n",
    "    plt.plot(train_ttf_sample_df, color='b')\n",
    "    ax2.set_ylabel('time to failure', color='b')\n",
    "    plt.legend(['time to failure'], loc=(0.01, 0.9))\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df)\n",
    "del train_ad_sample_df\n",
    "del train_ttf_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rows = 150_000\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "\n",
    "X_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['ave', 'std', 'max', 'min'])\n",
    "y_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['time_to_failure'])\n",
    "\n",
    "for segment in tqdm(range(segments)):\n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = pd.Series(seg['acoustic_data'].values)\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    \n",
    "    y_train.loc[segment, 'time_to_failure'] = y\n",
    "    \n",
    "    X_train.loc[segment, 'ave'] = x.mean()\n",
    "    X_train.loc[segment, 'std'] = x.std()\n",
    "    X_train.loc[segment, 'max'] = x.max()\n",
    "    X_train.loc[segment, 'min'] = x.min()\n",
    "    \n",
    "\n",
    "    \n",
    "    for windows in [10,100,1000]:\n",
    "        x_roll_std = x.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X_train.loc[segment, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X_train.loc[segment, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X_train.loc[segment, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X_train.loc[segment, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X_train.loc[segment, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X_train.loc[segment, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X_train.loc[segment, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X_train.loc[segment, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X_train.loc[segment, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X_train.loc[segment, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X_train.loc[segment, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X_train.loc[segment, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X_train.loc[segment, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X_train.loc[segment, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X_train.loc[segment, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X_train.loc[segment, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_train.loc[segment, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_train.loc[segment, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_train.loc[segment, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_train.loc[segment, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X_train.loc[segment, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X_train.loc[segment, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "print(X_train.isnull().sum())\n",
    "print(y_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[X_train.columns]\n",
    "\n",
    "y = y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110,120],\n",
    "    'max_features': [2, 3,5],\n",
    "    'min_samples_leaf': [10, 30, 50],\n",
    "    'min_samples_split': [10, 20, 30],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rfr, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, grid_predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, grid_predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, grid_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_regressor = xgb.XGBRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    max_depth = 110,\n",
    "    min_child_weight = 1.5,\n",
    "    n_estimators = 7500,                                                                  \n",
    "    seed = 42,\n",
    "    silent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt_predict = xgb_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, xgb_opt_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestRegressor(bootstrap = True, max_depth = 120, max_features = 5, random_state=42, n_estimators = 300, criterion='mae',  oob_score = True,\n",
    "                            n_jobs = -1, min_samples_leaf=10, min_samples_split = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = X_train.columns[(sel.get_support())]\n",
    "len(selected_feat)\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(bootstrap = True, max_depth = 120, max_features = 5, random_state=42, n_estimators = 300, criterion='mae',  oob_score = True,\n",
    "                            n_jobs = -1, min_samples_leaf=10, min_samples_split = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "xgb_opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cv_scores = cross_val_score(rfr, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test.values.flatten(), predictions)\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlabel('actual', fontsize=12)\n",
    "plt.ylabel('predicted', fontsize=12)\n",
    "plt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv', index_col='seg_id')\n",
    "\n",
    "X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)\n",
    "\n",
    "for seg_id in X_test.index:\n",
    "    seg = pd.read_csv('test/' + seg_id + '.csv')\n",
    "   \n",
    "    x = pd.Series(seg['acoustic_data'].values)\n",
    "    \n",
    "    X_test.loc[seg_id, 'ave'] = x.mean()\n",
    "    X_test.loc[seg_id, 'std'] = x.std()\n",
    "    X_test.loc[seg_id, 'max'] = x.max()\n",
    "    X_test.loc[seg_id, 'min'] = x.min()\n",
    "    for windows in [10,100,1000]:\n",
    "        x_roll_std = x.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        X_test.loc[seg_id, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X_test.loc[seg_id, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X_test.loc[seg_id, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X_test.loc[seg_id, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X_test.loc[seg_id, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X_test.loc[seg_id, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X_test.loc[seg_id, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X_test.loc[seg_id, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X_test.loc[seg_id, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X_test.loc[seg_id, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X_test.loc[seg_id, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X_test.loc[seg_id, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X_test.loc[seg_id, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X_test.loc[seg_id, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X_test.loc[seg_id, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X_test.loc[seg_id, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_test.loc[seg_id, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_test.loc[seg_id, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_test.loc[seg_id, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_test.loc[seg_id, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X_test.loc[seg_id, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X_test.loc[seg_id, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n",
    "\n",
    "\n",
    "submission['time_to_failure'] = rfr.predict(X_test)\n",
    "submission.to_csv('submission6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
